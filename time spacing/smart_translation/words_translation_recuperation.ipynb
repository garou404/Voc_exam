{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T15:54:34.675909200Z",
     "start_time": "2024-01-27T15:54:29.687412200Z"
    }
   },
   "id": "c2ba8b1b314d41d2"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-27T15:54:34.682902800Z",
     "start_time": "2024-01-27T15:54:34.682902800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                       words nature  translation\n0                        to (kid) themselves      v          NaN\n1                 the weeks crept on (crept)      v          NaN\n2             turned it (thrice) in his hand    NaN          NaN\n3                                maddeningly    NaN          NaN\n4               the (strain) of not laughing      n          NaN\n..                                       ...    ...          ...\n101           to be straining to (straining)    NaN          NaN\n102  it pelted straight at his face (pelted)      v          NaN\n103                   he reeled off (reeled)      v          NaN\n104                                    cling    NaN          NaN\n105                                 fetch sb    NaN          NaN\n\n[106 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>words</th>\n      <th>nature</th>\n      <th>translation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>to (kid) themselves</td>\n      <td>v</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>the weeks crept on (crept)</td>\n      <td>v</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>turned it (thrice) in his hand</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>maddeningly</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the (strain) of not laughing</td>\n      <td>n</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>to be straining to (straining)</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>102</th>\n      <td>it pelted straight at his face (pelted)</td>\n      <td>v</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>103</th>\n      <td>he reeled off (reeled)</td>\n      <td>v</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>cling</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>105</th>\n      <td>fetch sb</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>106 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = pd.read_csv('words_to_translate.csv', sep=';')\n",
    "df_words_test = df_words\n",
    "df_words_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "\n",
    "personal_pronouns = ['i', 'you', 'he', 'she', 'it', 'we', 'they']\n",
    "indefinite_pronouns = ['sth', 'sb']\n",
    "to = 'to'\n",
    "grammatical_article = 'the'\n",
    "def operation(row):\n",
    "    nature = ''\n",
    "    if pd.isnull(row['nature']) is False:\n",
    "        nature = row['nature'].lower()\n",
    "    words = row['words'].lower()\n",
    "    word = ''\n",
    "    indef_pronoun = None\n",
    "    if ('(' in words) & (')' in words):\n",
    "        pattern = r\"\\((.*?)\\)\"\n",
    "        word = re.findall(pattern, words)[0]\n",
    "    else:\n",
    "        words = words.split(' ')\n",
    "        if len(words) == 1:\n",
    "            word = words[0]\n",
    "        elif len(words) == 2:\n",
    "            for i in range(2):\n",
    "                for personal_pronoun in personal_pronouns:\n",
    "                    if personal_pronoun == words[i]:\n",
    "                        word = words[abs(i-1)]\n",
    "                for indefinite_pronoun in indefinite_pronouns:\n",
    "                    if indefinite_pronoun == words[i]:\n",
    "                        indef_pronoun = '['+words[i]+']'\n",
    "                        word = words[abs(i-1)]\n",
    "                if to == words[i]:\n",
    "                    word = words[abs(i-1)]\n",
    "                if nature != '':\n",
    "                    nature = 'v'\n",
    "                if grammatical_article == words[i]:\n",
    "                    word = words[abs(i-1)]\n",
    "                    if nature != '':\n",
    "                        nature = 'n'\n",
    "        elif len(words) > 2:\n",
    "            return 'too much word'\n",
    "    print(word)\n",
    "    translations = get_translation(word)\n",
    "    if translations == 0:\n",
    "        print()\n",
    "        return None\n",
    "    filtered_translations = []\n",
    "    #print(translations)\n",
    "    if nature != '':\n",
    "        if nature == 'v':\n",
    "            for i in range(len(translations)):\n",
    "                if nature == translations[i]['nature'][0]:\n",
    "                    filtered_translations.append(translations[i])\n",
    "            if indef_pronoun is not None:\n",
    "                filtered_translations = filter_indefinite_pronouns(filtered_translations, indef_pronoun)\n",
    "        else:\n",
    "            for i in range(len(translations)):\n",
    "                if nature == translations[i]['nature']:\n",
    "                    filtered_translations.append(translations[i])\n",
    "    else:\n",
    "        if indef_pronoun is not None:\n",
    "            translations = filter_indefinite_pronouns(translations, indef_pronoun)\n",
    "        filtered_translations = translations\n",
    "    #for translation in filtered_translations:\n",
    "    #    print(translation)\n",
    "    #    print()\n",
    "    #print()\n",
    "    return filtered_translations\n",
    "\n",
    "def filter_indefinite_pronouns(traductions, indef_pronoun):\n",
    "    return [trad for trad in traductions if indef_pronoun in trad['word']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kid\n",
      "4\n",
      "crept\n",
      "3\n",
      "thrice\n",
      "1\n",
      "maddeningly\n",
      "1\n",
      "strain\n",
      "3\n",
      "pedantically\n",
      "1\n",
      "twilight\n",
      "2\n",
      "boasting\n",
      "4\n",
      "coweb\n",
      "No translation found\n",
      "\n",
      "chug\n",
      "2\n",
      "chug\n",
      "2\n",
      "ghostly\n",
      "1\n",
      "dreadful\n",
      "2\n",
      "wail\n",
      "1\n",
      "scurrying\n",
      "1\n",
      "musty\n",
      "1\n",
      "yield\n",
      "3\n",
      "dreary\n",
      "1\n",
      "downpour\n",
      "1\n",
      "sodden\n",
      "1\n",
      "<td> (soaked, drenched)</td>\n",
      "<td class=\"To2\"> <span class=\"dsense\" data-dict=\"enfr\" data-lang=\"fr\">(<i>sol</i>)</span></td>\n",
      "<td class=\"FrEx\" colspan=\"2\"><span dir=\"ltr\">We walked slowly across the sodden field, our boots sinking into the mud.</span></td>\n",
      "<td class=\"ToEx\" colspan=\"2\"><span dir=\"ltr\"><i>Nous marchions lentement à travers le champ détrempé, nos bottes s'enfonçant dans la boue.</i></span></td>\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[101], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_words_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtranslation\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf_words_test\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43moperation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m df_words_test\n",
      "File \u001B[1;32mD:\\logiciel\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:10361\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001B[0m\n\u001B[0;32m  10347\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[0;32m  10349\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[0;32m  10350\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  10351\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  10359\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[0;32m  10360\u001B[0m )\n\u001B[1;32m> 10361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\logiciel\\miniconda3\\lib\\site-packages\\pandas\\core\\apply.py:916\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[0;32m    914\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw(engine\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine, engine_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine_kwargs)\n\u001B[1;32m--> 916\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\logiciel\\miniconda3\\lib\\site-packages\\pandas\\core\\apply.py:1063\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1061\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m   1062\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mengine \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 1063\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1064\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1065\u001B[0m         results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_series_numba()\n",
      "File \u001B[1;32mD:\\logiciel\\miniconda3\\lib\\site-packages\\pandas\\core\\apply.py:1081\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1078\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1079\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[0;32m   1080\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[1;32m-> 1081\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunc(v, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs)\n\u001B[0;32m   1082\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[0;32m   1083\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n\u001B[0;32m   1085\u001B[0m             results[i] \u001B[38;5;241m=\u001B[39m results[i]\u001B[38;5;241m.\u001B[39mcopy(deep\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[98], line 39\u001B[0m, in \u001B[0;36moperation\u001B[1;34m(row)\u001B[0m\n\u001B[0;32m     37\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoo much word\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28mprint\u001B[39m(word)\n\u001B[1;32m---> 39\u001B[0m translations \u001B[38;5;241m=\u001B[39m \u001B[43mget_translation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mword\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m translations \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28mprint\u001B[39m()\n",
      "Cell \u001B[1;32mIn[100], line 41\u001B[0m, in \u001B[0;36mget_translation\u001B[1;34m(word)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m word\u001B[38;5;241m.\u001B[39mstrip() \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msodden\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m     40\u001B[0m     \u001B[38;5;28mprint\u001B[39m(block[y][\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m---> 41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mblock\u001B[49m\u001B[43m[\u001B[49m\u001B[43my\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspan\u001B[39m\u001B[38;5;124m'\u001B[39m, class_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdsense\u001B[39m\u001B[38;5;124m'\u001B[39m): \u001B[38;5;66;03m# when indication with the translation\u001B[39;00m\n\u001B[0;32m     42\u001B[0m     traduction_context \u001B[38;5;241m=\u001B[39m block[y][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mspan\u001B[39m\u001B[38;5;124m'\u001B[39m, class_\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdsense\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mget_text()\n\u001B[0;32m     43\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m block[y][\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mfind(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mem\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "df_words_test['translation'] = df_words_test.apply(operation, axis=1)\n",
    "df_words_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "def get_translation(word):\n",
    "    r = requests.get('https://www.wordreference.com/enfr/'+word)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    if soup.find('p', attrs={'id':'noEntryFound'}):\n",
    "        print('No translation found')\n",
    "        return 0\n",
    "    print(len(soup.find_all('table', class_='WRD')))\n",
    "    translations_tr_list = (soup.find_all('table', class_='WRD')[0].find_all('tr', class_=['even', 'odd']))\n",
    "\n",
    "    translation_blocks = []\n",
    "    block_temp = []\n",
    "    for i in range(len(translations_tr_list)):\n",
    "        if i != 0:\n",
    "            if translations_tr_list[i].attrs.get('class')[0] != translations_tr_list[i - 1].attrs.get('class')[0]:\n",
    "                translation_blocks.append(block_temp)\n",
    "                block_temp = []\n",
    "        block_temp.append(translations_tr_list[i].find_all('td'))\n",
    "    translation_blocks.append(block_temp)\n",
    "\n",
    "    array_translations = []\n",
    "    translations = {}\n",
    "\n",
    "    for block in translation_blocks:\n",
    "        if block[0][0].find('em'): # check for nature\n",
    "            nature = block[0][0].find('em')\n",
    "            nature.extract()\n",
    "        if block[0][0].find('a'): # remove a tag from english\n",
    "            block[0][0].find('a').extract()\n",
    "        word = block[0][0].get_text()\n",
    "        figurative = ''\n",
    "        if block[0][1].find('i'):\n",
    "            figurative = block[0][1].find('i').get_text()\n",
    "        definition = figurative+''.join(block[0][1].find_all(string=True, recursive=False)).strip()\n",
    "        translations['word'] = word.strip()\n",
    "        translations['nature'] = nature.get_text()\n",
    "        if definition != '':\n",
    "            translations['definition'] = definition.replace('\\xa0', '').strip()\n",
    "        for y in range(len(block)):\n",
    "            if word.strip() == 'sodden':\n",
    "                print(block[y][1])\n",
    "            if block[y][1].find('span', class_='dsense'): # when indication with the translation\n",
    "                traduction_context = block[y][1].find('span', class_='dsense').get_text()\n",
    "                if block[y][2].find('em'):\n",
    "                    block[y][2].find('em').extract()\n",
    "                if block[y][2].find_all('a'):\n",
    "                    for a in block[y][2].find_all('a'):\n",
    "                        a.extract()\n",
    "                traduction = block[y][2].get_text().strip()\n",
    "                translations['trad-'+str(y)] = traduction_context+traduction\n",
    "            elif block[y][1].has_attr('class') and 'FrEx' in block[y][1]['class']: # example\n",
    "                if block[y][1].find('span', class_='tooltip'): # remove tooltip message from example\n",
    "                    block[y][1].find('span', class_='tooltip').extract()\n",
    "                translations['example-eng-'+str(y)] = block[y][1].get_text().strip()\n",
    "            elif block[y][1].has_attr('class') and 'ToEx' in block[y][1]['class']: # example\n",
    "                if block[y][1].find('span', class_='tooltip'): # remove tooltip message from example\n",
    "                    block[y][1].find('span', class_='tooltip').extract()\n",
    "                translations['example-fr-'+str(y)] = block[y][1].get_text().strip()\n",
    "            else:  # translation\n",
    "                if block[y][2].find('em'):\n",
    "                    block[y][2].find('em').extract()\n",
    "                if block[y][2].find_all('a'):\n",
    "                    for a in block[y][2].find_all('a'):\n",
    "                        a.extract()\n",
    "                traduction = block[y][2].get_text().strip()\n",
    "                translations['trad-'+str(y)] = traduction\n",
    "        array_translations.append(translations)\n",
    "        translations = {}\n",
    "    return array_translations"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
